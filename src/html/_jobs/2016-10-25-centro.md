---
layout: job
expire: 2016-11-25
title: Data Engineer
company: |
  Centro
location: San Francisco
level: Intermediate, Senior
remote: No
summary: |
  We are seeking forward-thinking Data Engineer to join Big Data team. You will be involved in the design and implementation of Big Data Platform based on Hadoop ecosystem. We're looking for a Data Engineer who has passion for data processing and the challenges presented by large volumes of data at high velocity.
admin: hannah.segall@centro.net
application_url: https://app.jobvite.com/j?aj=oNex3fwl&s=Underscore
instructions: |
  Apply online. Click "Apply Now" below to get started.
citizenship: |
  US Citizens preferred
---

<!-- break -->

## About the Product and Engineering Team

At Centro, we’ve always been about making people’s lives better—from our employees to our clients. Today, we’re building a unified platform to execute every digital media advertising transaction, thus providing a new level of automation and intelligence in ad tech. This is an enormous task that will disrupt an industry and improve the lives of those who work within it. 

To do this, we’re aggressively growing our team of engineers, product developers and designers. We are imaginative, passionate, determined and relentless in our efforts. Of course, we are fascinated by the complexity of engineering problems at this scale—it’s what brings bright minds together. But what keeps us coming back (and why we love coming to work everyday) is the chance to improve how work gets done: freeing up people’s time so that they can dream bigger and make life better.

Come build something amazing with us.

## About the Role

We are seeking forward-thinking Data Engineer to join Big Data team. You will be involved in the design and implementation of Big Data Platform based on Hadoop ecosystem. We're looking for a Data Engineer who has passion for data processing and the challenges presented by large volumes of data at high velocity.

## Core Responsibilities

- Implement scalable, fault tolerant and accurate ETL pipelines that work in a distributed Hadoop environment.
- Gather and process raw data at scale from diversified sources into Hadoop.
- Build enterprise business analytics and reporting applications on Hadoop.
- Develop platform services to operate the big data applications at scale.

## Qualifications

- Proven experience working with various components of Hadoop ecosystem: Spark, Hive, Impala, Kafka, Oozie.
- Proficiency with relational databases and SQL queries (MySQL, Oracle or similar).
- Understanding of how to handle high velocity, high volume data events.
- Understanding of factors affecting performance of ETL processes and SQL queries, ability to work on performance tuning.
- Experience implementing data pipelines moving large volumes of data a day.
- Experience in implementing application in Scala on SPARK.
- Experience with tools such as Git, Jenkins, Jira, IntelliJ.
- Ability to work independently as well as part of the team.
- Strong aptitude toward problem solving and working with large data sets.
- Have a Bachelor’s degree in computer science or software engineering.
- Experience with other big data technologies such as Cassandra, MongoDB, Elastic Search, etc.
- Knowledge of HBase.
- Experience coding in Python.
- Experience with BI tools such as Pentaho, Tableu, etc.
- Having a passion and knowledge of AdTech industry.

Centro is an Equal Opportunity Employer and does not discriminate against any employee or applicant on the basis of race, gender, age, disability or any other basis protected under the law.
