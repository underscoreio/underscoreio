---
layout: post
title: "Getting into other people's code"
author: Richard Dallaway
---

I admit it. I quite like studying other people's code.
I realize it's agony for some. A chore. A distraction from the real work of writing new code. 
But I suppose we've done enough code reviews to have developed an approach to the code.

There are a few key items we investigate, and in this post I'll outline the top five most important ones.

<!-- break -->

We're not talking here about a review of a pull request.
I mean a longer process, which some call a "code audit".
This is when we're taking a broader view of an entire code base.
It typically takes a couple of weeks to complete.

In time order, here are the five key items.

# 1. Why are we reviewing the code?

There's usually a lot of code to look at, and many aspects that could be focussed on.
To narrow the scope, and get some results out quickly, we ask _why_ we're reviewing the code.

A few examples of why code needs reviewing:

- the team is new and wants external guidance on sensible practices for what they want to achieve, or some guidance on idioms.

- the company is buying in the code, and want to know if what they have is of suitable quality.

- the team has changed, and no-one knows how the code works anymore.

- the team has tried different approaches (for example, to [error handling](https://underscore.io/blog/posts/2015/02/23/designing-fail-fast-error-handling.html)) and wants guidance on what to take forward as a standard approach.

- the team wants to take a stronger functional programming approach to the code base, and would like suggestions on areas where they are struggling.

There's a wide range of reasons there, and many of them are not really about the code. They are about team aspirations.

But there are also specific concerns a customer might have.
They come out of answers to the question: "What are you worried about?". 
The most popular answer to that questions is perhaps "maintainability".

Having figured out why we reviewing code, we can ask the second question.

# 2. What is the code supposed to do?

There's usually a high-level answer to this: it's a store to sell socks; it's a reporting engine for the business; it lets advertisers search inventory.

There's often detailed answers too. These might be key types and method signatures, database structures, or diagrams with lines between message queues.

Sadly there's often little between those.  By "what is the code supposed to do?" I'm looking for a description of the problem being solved by some module, and the approach taken.

What do I mean by that? Well, when you're building something there will be a few ways to go at it. The choice you make could be specific to the concerns you have, or might be arbitrary, or historic, or inherited.  Usually trade-offs are made. The source code and documentation rarely tell you what is intended and what is incidental.

To be able to effectively review code often means reconstructing these problems, and then the solutions. "Is this any good?" is hard to answer if you don't know what it is supposed to be doing.  And it is not only a pain for review, but also for any developer having to pick up the code in the future.

# 3. Sample an execution path

In truth step 2 usually goes hand-in-hand with step 3.  Here we're looking at the way the code flows, figuring out the layers of software. Where do the inputs come from? What are the outputs? What's the path between look like?

For a web API, this would be working through endpoints. For a distributed system, it means chasing messages.
It could also be the code paths executed by tests.

This is where most of the work is done. We're seeing the style of the code, the idioms in use, the common patterns.  Most recommendations from the review report will be generated in this section.

# 4. It's all about the people

That third step generates questions. Having the team available to answer those questions helps a great deal.

So does having access to the code repository. How does the team work? How have issues been communicated to the team? What's gone on in pull requests?  The social side of software is as big a point of review as the code.

It's also important to acknowledge that review is not about bashing the code or the developers.

In the heat of day-to-day coding we produce tangles and shoe-horn in solutions to ship the code. Shipping working product is the game, and I have every respect for the process developers are going through. They are getting to grips with the problem for the first time, sometimes the domain for the first time, weaving a solution, and getting into the hands of users.
 It's easy to come to a code base after the fact and say "I wouldn't have done it like that".  That ignores all the learning that's gone on creating that code. The review is more about understanding the concerns and needs of the project and helping it move in the right direction.

# 5. Automated analysis

The last thing is to apply automation. And in many ways the least useful. It's more an additional sanity check.

You do get a good idea of tests by generating a code coverage report.  You can compute various metrics over the code, or look for common smells (or warts).

# Summary

When reviewing a whole code base:

- ask why are we reviewing the code. What is important to the business or team?
- figure out what is the code supposed to do. What problem is a module solving, and what approach have we taken?
- follow execution paths to get an understanding of how the code structure and flow
- talk to the people involved, get a feel for how the work is carried out.
- run automated analysis as an additional sanity check.

Use the comments below to share your tips for reviewing a code base.




